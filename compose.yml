name: 'jit'
services:
  main:
    build:
      context: ./
      target: development
      args:
        COMMIT_HASH: 'abcdef'
    command: [ '/bin/sh', './docker/main/entrypoint.sh' ]
    restart: always
    tty: true
    stdin_open: true
    user: "${UID:-1000}:${GID:-1000}"
    ports:
      - "127.0.0.1:3300:3000"
    volumes:
      - ./:/main
      - main_tmp:/main/tmp
      - main_vendor:/main/vendor
      - main_modules:/main/node_modules
    networks:
      - backend
      - frontend
    depends_on:
      - primary
      - replica
      - elasticsearch
      - kafka
      - redis
      - minio
    environment:
      # Rails Configuration
      - RAILS_ENV=development
      - RACK_ENV=development
      - RAILS_MAX_THREADS=5
      - BUNDLE_PATH=/main/vendor/bundle
      - BUNDLE_JOBS=4
      # App Configuration
      - NAME=UMAXICA
      - PORT=3000
      # Active Record Encryption
      - ACTIVE_RECORD_ENCRYPTION_PRIMARY_KEY=yiPQNMtjJOZ5dOC9JnzW68zp9DUs5Jum
      - ACTIVE_RECORD_ENCRYPTION_DETERMINISTIC_KEY=QXV9b9HnerqaJ71d4EPJLvBGUkCteppN
      - ACTIVE_RECORD_ENCRYPTION_KEY_DERIVATION_SALT=L1ddJpO64JUJXoycn4GZ9PPkV7eg8trv
      # Identifiers
      - SINGLETON_DEFAULT_SALT=hoge
      - IDENTIFIER_REGION_CODE=392
      - IDENTIFIER_INSTANCE_ID=0123456789
      # Domain URLs
      - APEX_CORPORATE_URL=com.localhost
      - APEX_SERVICE_URL=app.localhost
      - APEX_STAFF_URL=org.localhost
      - API_CORPORATE_URL=api.com.localhost
      - API_SERVICE_URL=api.app.localhost
      - API_STAFF_URL=api.org.localhost
      - AUTH_SERVICE_URL=auth.app.localhost
      - AUTH_STAFF_URL=auth.org.localhost
      - DOCS_CORPORATE_URL=docs.com.localhost
      - DOCS_SERVICE_URL=docs.app.localhost
      - DOCS_STAFF_URL=docs.org.localhost
      - NEWS_CORPORATE_URL=news.com.localhost
      - NEWS_SERVICE_URL=news.app.localhost
      - NEWS_STAFF_URL=news.org.localhost
      - HELP_CORPORATE_URL=help.com.localhost
      - HELP_SERVICE_URL=help.app.localhost
      - HELP_STAFF_URL=help.org.localhost
      - EDGE_CORPORATE_URL=localhost:5170
      - EDGE_SERVICE_URL=localhost:5171
      - EDGE_STAFF_URL=localhost:5172
      # Database Configuration
      - POSTGRESQL_USER=root
      - POSTGRESQL_PASSWORD=password
      - POSTGRESQL_PORT=5432
      - POSTGRESQL_UNIVERSAL_PUB=primary
      - POSTGRESQL_UNIVERSAL_SUB=replica
      - POSTGRESQL_CONTACT_PUB=primary
      - POSTGRESQL_CONTACT_SUB=replica
      - POSTGRESQL_IDENTIFIER_PUB=primary
      - POSTGRESQL_IDENTIFIER_SUB=replica
      - POSTGRESQL_PROFILE_PUB=primary
      - POSTGRESQL_PROFILE_SUB=replica
      - POSTGRESQL_TOKEN_PUB=primary
      - POSTGRESQL_TOKEN_SUB=replica
      - POSTGRESQL_BUSINESS_PUB=primary
      - POSTGRESQL_BUSINESS_SUB=replica
      - POSTGRESQL_MESSAGE_PUB=primary
      - POSTGRESQL_MESSAGE_SUB=replica
      - POSTGRESQL_NOTIFICATION_PUB=primary
      - POSTGRESQL_NOTIFICATION_SUB=replica
      - POSTGRESQL_CACHE_PUB=primary
      - POSTGRESQL_CACHE_SUB=replica
      - POSTGRESQL_SPECIALITY_PUB=primary
      - POSTGRESQL_SPECIALITY_SUB=replica
      - POSTGRESQL_STORAGE_PUB=primary
      - POSTGRESQL_STORAGE_SUB=replica
      # Kafka Configuration
      - KAFKA_BROKERS=kafka:29092
      # Search Configuration
      - OPENSEARCH_DEFAULT_URL=http://elasticsearch:9200
      # Mail Configuration
      - RESEND_SMTP_ENDPOINT=smtp.resend.com
      - RESEND_SMTP_USER_NAME=resend
      # Object Storage Configuration
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
  minio:
    image: minio/minio
    ports:
      - "127.0.0.1:${MINIO_API_PORT:-19000}:9000"
      - "127.0.0.1:${MINIO_CONSOLE_PORT:-19001}:9001"
    volumes:
      - minio-volume:/data
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
  primary:
    image: postgres:16.6
    command: -c 'config_file=/etc/postgresql/postgresql.conf' -c 'hba_file=/etc/postgresql/pg_hba.conf'
    networks:
      - backend
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: password
      TZ: UTC
      POSTGRES_HOST_AUTH_METHOD: trust # NOTE: Development only
      POSTGRES_INITDB_WAL_LEVEL: replica # wal_level setting
      POSTGRES_INITDB_MAX_WAL_SENDERS: 10 # max_wal_senders setting
      POSTGRES_INITDB_MAX_REPLICATION_SLOTS: 10 # max_replication_slots setting
      POSTGRES_DB: db
    tmpfs: /var/lib/postgresql/data
    ports:
      - "127.0.0.1:5435:5432"
    volumes:
      - ./docker/psql-pub/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./docker/psql-pub/pg_hba.conf:/etc/postgresql/pg_hba.conf
      - ./docker/psql-pub/init.sh:/docker-entrypoint-initdb.d/init.sh
  replica:
    image: postgres:16.6
    entrypoint: /entrypoint.sh
    networks:
      - backend
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: password
      TZ: UTC
      POSTGRES_HOST_AUTH_METHOD: trust # NOTE: Development only
      POSTGRES_DB: db
    ports:
      - "127.0.0.1:5436:5432"
    tmpfs: /var/lib/postgresql/data
    volumes:
      - ./docker/psql-sub/entrypoint.sh:/entrypoint.sh
      - ./docker/psql-sub/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./docker/psql-sub/pg_hba.conf:/etc/postgresql/pg_hba.conf
    depends_on:
      - primary
  redis:
    image: valkey/valkey:8.1.1-alpine3.21
    ports:
      - "127.0.0.1:6380:6379"
    networks:
      - backend
    volumes:
      - redis-volume:/data
  zookeeper:
    image: confluentinc/cp-zookeeper:7.9.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - backend
  kafka:
    image: confluentinc/cp-kafka:7.9.0
    ports:
      - "127.0.0.1:${KAFKA_BROKER_PORT:-19092}:9092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:${KAFKA_BROKER_PORT:-19092},PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    networks:
      - backend
  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui:v1.2.0
    ports:
      - "127.0.0.1:${KAFKA_UI_PORT:-18080}:8080"
    depends_on:
      - kafka
    restart: always
    environment:
      KAFKA_CLUSTERS_0_NAME: local-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    networks:
      - backend
  elasticsearch:
    image: opensearchproject/opensearch:2.11.1
    container_name: elasticsearch
    environment:
      - cluster.name=opensearch-cluster
      - node.name=elasticsearch
      - discovery.type=single-node
      - bootstrap.memory_lock=false
      - "OPENSEARCH_JAVA_OPTS=-Xms256m -Xmx256m"
      - DISABLE_SECURITY_PLUGIN=true
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - "network.host=0.0.0.0"
      - "http.host=0.0.0.0"
      - "transport.host=localhost"
      - "http.port=9200"
      - "transport.tcp.port=9300"
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - elasticsearch-volume:/usr/share/opensearch/data
    ports:
      - "127.0.0.1:${ES_HTTP_PORT:-19200}:9200"
      - "127.0.0.1:${ES_TCP_PORT:-19300}:9300"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=10s || exit 1" ]
      interval: 30s
      timeout: 15s
      retries: 10
      start_period: 120s
  elasticsearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.11.1
    container_name: elasticsearch-dashboards
    environment:
      OPENSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: 'true'
      SERVER_HOST: '0.0.0.0'
      SERVER_PORT: 5601
      LOGGING_LEVEL: info
      OPENSEARCH_REQUEST_TIMEOUT: 120000
      OPENSEARCH_PING_TIMEOUT: 30000
    ports:
      - "127.0.0.1:${ES_DASHBOARDS_PORT:-15601}:5601"
    networks:
      - backend
    depends_on:
      elasticsearch:
        condition: service_healthy
  # grafana:
  #   image: grafana/grafana:latest
  #   ports:
  #     - 8000:3000
  #   volumes:
  #     - grafana-volume:/var/lib/grafana
  #     # Add config files if available
  #     # - ./docker/grafana/provisioning:/etc/grafana/provisioning
  #   networks:
  #     - backend
  #   depends_on:
  #     - prometheus
  #     - loki
  #     - tempo
  #     - elasticsearch
  #   environment:
  #     GF_SECURITY_ADMIN_USER: admin
  #     GF_SECURITY_ADMIN_PASSWORD: admin
  #     GF_PATHS_PROVISIONING: /etc/grafana/provisioning
  # prometheus:
  #   image: prom/prometheus:latest
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - prometheus-volume:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #     - '--web.enable-lifecycle'
  #   networks:
  #     - observility
  #   restart: always
  # # Log collection
  # loki:
  #   image: grafana/loki:latest
  #   ports:
  #     - "3100:3100"
  #   volumes:
  #     - loki-volume:/tmp/loki
  #   command: -config.file=/etc/loki/local-config.yaml
  #   networks:
  #     - observility
  #   restart: always
  # # Distributed tracing
  # tempo:
  #   image: grafana/tempo:latest
  #   command: -config.file=/etc/tempo.yaml  # .yaml から .yml に変更
  #   volumes:
  #   - ./docker/tempo/tempo.yaml:/etc/tempo.yaml  # ファイル名とパスを変更
  #   - tempo-volume:/tmp/tempo
  #   ports:
  #     - "14268:14268"  # jaeger ingest
  #     - "3200:3200"   # tempo
  #     - "9095:9095" # tempo grpc
  #     - "4317:4317"  # otlp grpc
  #     - "4318:4318"  # otlp http
  #     - "9411:9411"   # zipkin
  #   depends_on:
  #     - main
volumes:
  psql-pub-volume:
  psql-sub-volume:
  redis-volume:
  kafka-broker-volume:
  elasticsearch-volume:
  minio-volume:
  main_tmp:
  main_vendor:
  main_modules:
networks:
  backend:
  frontend:
